{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtagKsxbXfOu",
    "outputId": "dfa2826f-731f-4105-dde8-747987a574f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xw-MwG_lYPMi"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Word2Vec is a powerful tool\",\n",
    "    \"Machine learning is fascinating\",\n",
    "    \"Text mining is a part of NLP\",\n",
    "    \"Word embeddings capture semantic information\"\n",
    "]\n",
    "\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "model.save(\"word2vec.model\")\n",
    "\n",
    "word_vectors = model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ANhPJYsYR-F",
    "outputId": "8046d43f-22e6-416e-9488-2f7a454ef9ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of 'natural':\n",
      "[-8.7274043e-03  2.1301224e-03 -8.7386504e-04 -9.3187429e-03\n",
      " -9.4274785e-03 -1.4103638e-03  4.4322358e-03  3.7039935e-03\n",
      " -6.4985557e-03 -6.8723583e-03 -4.9994658e-03 -2.2865026e-03\n",
      " -7.2503299e-03 -9.6027302e-03 -2.7437326e-03 -8.3626304e-03\n",
      " -6.0387314e-03 -5.6703682e-03 -2.3437263e-03 -1.7071365e-03\n",
      " -8.9565096e-03 -7.3558721e-04  8.1524728e-03  7.6905079e-03\n",
      " -7.2058719e-03 -3.6666191e-03  3.1184379e-03 -9.5699849e-03\n",
      "  1.4759584e-03  6.5241512e-03  5.7464754e-03 -8.7625179e-03\n",
      " -4.5168600e-03 -8.1401914e-03  4.6372228e-05  9.2628645e-03\n",
      "  5.9728688e-03  5.0672246e-03  5.0607836e-03 -3.2426899e-03\n",
      "  9.5517728e-03 -7.3563815e-03 -7.2704921e-03 -2.2648417e-03\n",
      " -7.7823555e-04 -3.2162669e-03 -5.9237826e-04  7.4884607e-03\n",
      " -6.9726864e-04 -1.6252064e-03  2.7444721e-03 -8.3584655e-03\n",
      "  7.8558754e-03  8.5354699e-03 -9.5836623e-03  2.4457709e-03\n",
      "  9.9040167e-03 -7.6658656e-03 -6.9666184e-03 -7.7364552e-03\n",
      "  8.3957212e-03 -6.8159611e-04  9.1440771e-03 -8.1577897e-03\n",
      "  3.7427275e-03  2.6348510e-03  7.4317772e-04  2.3279861e-03\n",
      " -7.4689318e-03 -9.3574496e-03  2.3541783e-03  6.1484347e-03\n",
      "  7.9851272e-03  5.7357764e-03 -7.7714317e-04  8.3060768e-03\n",
      " -9.3359742e-03  3.4063964e-03  2.6710413e-04  3.8566000e-03\n",
      "  7.3850341e-03 -6.7251986e-03  5.5843568e-03 -9.5218858e-03\n",
      " -8.0475799e-04 -8.6886901e-03 -5.0980211e-03  9.2888381e-03\n",
      " -1.8586367e-03  2.9140499e-03  9.0709710e-03  8.9374604e-03\n",
      " -8.2077496e-03 -3.0123789e-03  9.8862397e-03  5.1037837e-03\n",
      " -1.5877021e-03 -8.6913416e-03  2.9613981e-03 -6.6754073e-03]\n"
     ]
    }
   ],
   "source": [
    "word = \"natural\"\n",
    "vector = word_vectors[word]\n",
    "print(f\"Vector representation of '{word}':\\n{vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zZK9AAiYT5a",
    "outputId": "538ff9a4-0811-4b84-a1fc-408282c8a27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'natural':\n",
      "[('learning', 0.16694533824920654), ('love', 0.1389191448688507), ('machine', 0.13148725032806396), ('embeddings', 0.09762486070394516), ('of', 0.0717507153749466)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = word_vectors.most_similar(\"natural\", topn=5)\n",
    "print(f\"Words similar to 'natural':\\n{similar_words}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
